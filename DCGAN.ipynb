{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORSE4ZhxswPjZ/XIpJSkdB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLLSCKR/Paper_Implementation/blob/main/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DCGAN(Deep Convolutional Generative Adversarial Network)\n",
        "\n",
        "### GAN의 문제점\n",
        "1. Generator or Discriminator 둘 중 하나가 수렴하지 않으면 과적합이 발생할 수 있다.\n",
        "2. 때때로 generator는 소수의 sample 종류만 생성한다. 이를 mode collapse(모드 붕괴)라고 한다.\n",
        "\n",
        "### DCGAN이 사용한 기술\n",
        "위의 GAN의 문제를 해결하고 안정적인 학습을 보장하기 위해서 DCGAN은 아래의 3가지 기술을 사용한다.\n",
        "1. Fully Connected Layer를 제거하고 Convolutional Layer만 사용한다.\n",
        "2. Pooling layer를 사용하는 대신 Strided Convolution을 사용하여 Down-Sampling 수행\n",
        "3. Hidden Layer 간에 tanh 대신 ReLU/leakyReLU 활성화 함수 사용"
      ],
      "metadata": {
        "id": "81IN1-AavzoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MtrWQigUUtvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = \"pytorch_practice\"\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/pytorch_practice/GAN/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQoCz_Q9Us83",
        "outputId": "2436b50c-dc96-427c-cbab-7a83cfdb1164"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/pytorch_practice/GAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils"
      ],
      "metadata": {
        "id": "oxS4mf32UsWw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e5JoUdzlveXi"
      },
      "outputs": [],
      "source": [
        "data_path = './Data/mnist'\n",
        "out_path = 'output'\n",
        "log_file = os.path.join(out_path, 'log.txt')\n",
        "batch_size = 128\n",
        "image_channel = 1\n",
        "\n",
        "z_dim = 100\n",
        "\n",
        "g_hidden = 64\n",
        "x_dim = 64\n",
        "d_hidden = 64\n",
        "epoch_num = 25\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "lr = 2e-4\n",
        "seed = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "6ITkkh2va5RE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator Network"
      ],
      "metadata": {
        "id": "JF0JOt_ZbJR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        #1st layer\n",
        "        nn.ConvTranspose2d(z_dim, g_hidden * 8, 4, 1, 0, bias = False),\n",
        "        nn.BatchNorm2d(g_hidden * 8),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        #2nd layer\n",
        "        nn.ConvTranspose2d(g_hidden * 8, g_hidden * 4, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(g_hidden * 4),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        #3rd layer\n",
        "        nn.ConvTranspose2d(g_hidden * 4, g_hidden * 2, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(g_hidden * 2),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        #4th layer\n",
        "        nn.ConvTranspose2d(g_hidden * 2, g_hidden, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(g_hidden),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        #output layer\n",
        "        nn.ConvTranspose2d(g_hidden, image_channel, 4, 2, 1, bias = False),\n",
        "        nn.Tanh()\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.main(input)"
      ],
      "metadata": {
        "id": "Lx9JFPZPa5L1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    m.weight.data.normal_(0.0, 0.02)\n",
        "  \n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    m.weight.data.normal_(1.0, 0.02)\n",
        "    m.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "rd92k3NJa5JQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netG = Generator().to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLCJHwF0a5Gp",
        "outputId": "7aa8aeaf-b5de-491b-fafd-15087559a57f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(netG, input_size = (100, 1, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfKuk1_Za5EU",
        "outputId": "44215699-d360-44d1-a822-1d156edadf51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   ConvTranspose2d-1            [-1, 512, 4, 4]         819,200\n",
            "       BatchNorm2d-2            [-1, 512, 4, 4]           1,024\n",
            "              ReLU-3            [-1, 512, 4, 4]               0\n",
            "   ConvTranspose2d-4            [-1, 256, 8, 8]       2,097,152\n",
            "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
            "              ReLU-6            [-1, 256, 8, 8]               0\n",
            "   ConvTranspose2d-7          [-1, 128, 16, 16]         524,288\n",
            "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "  ConvTranspose2d-10           [-1, 64, 32, 32]         131,072\n",
            "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
            "             ReLU-12           [-1, 64, 32, 32]               0\n",
            "  ConvTranspose2d-13            [-1, 1, 64, 64]           1,024\n",
            "             Tanh-14            [-1, 1, 64, 64]               0\n",
            "================================================================\n",
            "Total params: 3,574,656\n",
            "Trainable params: 3,574,656\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 2.88\n",
            "Params size (MB): 13.64\n",
            "Estimated Total Size (MB): 16.51\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator Network"
      ],
      "metadata": {
        "id": "eClG7rByvyeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "        #1st layer\n",
        "        nn.Conv2d(image_channel, d_hidden, 4, 2, 1, bias = False),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "\n",
        "        #2nd layer\n",
        "        nn.Conv2d(d_hidden, d_hidden * 2, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(d_hidden * 2),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "\n",
        "        #3rd layer\n",
        "        nn.Conv2d(d_hidden * 2, d_hidden * 4, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(d_hidden * 4),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "\n",
        "        #4th layer\n",
        "        nn.Conv2d(d_hidden * 4, d_hidden * 8, 4, 2, 1, bias = False),\n",
        "        nn.BatchNorm2d(d_hidden * 8),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "\n",
        "        #output layer\n",
        "        nn.Conv2d(d_hidden*8, 1, 4, 1, 0, bias = False),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, input):\n",
        "    return self.main(input).view(-1, 1).squeeze(1)\n",
        "\n",
        "    \"\"\"\n",
        "    squeeze method\n",
        "      Returns a tensor with all the dimensions of input of size 1 removed.\n",
        "      For example, if input is of shape: (A \\times 1 \\times B \\times C \\times 1 \\times D)(A×1×B×C×1×D) then the out tensor will be of shape: (A \\times B \\times C \\times D)(A×B×C×D).\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "DbpTkrgpgDWZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netD = Discriminator().to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIukOst8gDUR",
        "outputId": "b45f135d-402e-444b-9036-40456a640a75"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(netD, input_size = (1, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeSw0XAGgDSD",
        "outputId": "820adb77-a350-4841-a744-19e5da9d8f9e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           1,024\n",
            "         LeakyReLU-2         [-1, 64, 112, 112]               0\n",
            "            Conv2d-3          [-1, 128, 56, 56]         131,072\n",
            "       BatchNorm2d-4          [-1, 128, 56, 56]             256\n",
            "         LeakyReLU-5          [-1, 128, 56, 56]               0\n",
            "            Conv2d-6          [-1, 256, 28, 28]         524,288\n",
            "       BatchNorm2d-7          [-1, 256, 28, 28]             512\n",
            "         LeakyReLU-8          [-1, 256, 28, 28]               0\n",
            "            Conv2d-9          [-1, 512, 14, 14]       2,097,152\n",
            "      BatchNorm2d-10          [-1, 512, 14, 14]           1,024\n",
            "        LeakyReLU-11          [-1, 512, 14, 14]               0\n",
            "           Conv2d-12            [-1, 1, 11, 11]           8,192\n",
            "          Sigmoid-13            [-1, 1, 11, 11]               0\n",
            "================================================================\n",
            "Total params: 2,763,520\n",
            "Trainable params: 2,763,520\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 28.33\n",
            "Params size (MB): 10.54\n",
            "Estimated Total Size (MB): 39.06\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning and Evaluation"
      ],
      "metadata": {
        "id": "5dc8T3YeiwE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr = lr, betas = (0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr = lr, betas = (0.5, 0.999))"
      ],
      "metadata": {
        "id": "CVT050pMgDPt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dset.MNIST(root = data_path, download = True, \n",
        "                     transform = transforms.Compose([\n",
        "                         transforms.Resize(x_dim),\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.5,), (0.5,))\n",
        "                     ]))\n",
        "assert dataset"
      ],
      "metadata": {
        "id": "PWBqPxsugDNX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqUqGpQdgDKy",
        "outputId": "fec65ad6-85b8-4b62-c2ee-b13b90b40f4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Learning!!!\n",
        "\n",
        "viz_noise = torch.randn(batch_size, z_dim, 1, 1, device = device)\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "  for i, data in enumerate(dataloader):\n",
        "    x_real = data[0].to(device)\n",
        "    r_label = torch.full((x_real.size(0),), real_label, device = device).float()\n",
        "    f_label = torch.full((x_real.size(0),), fake_label, device = device).float()\n",
        "\n",
        "    # update D with real data\n",
        "    netD.zero_grad()\n",
        "    y_real = netD(x_real)\n",
        "\n",
        "    loss_D_real = criterion(y_real, r_label)\n",
        "    loss_D_real.backward()\n",
        "\n",
        "    # update D with fake data\n",
        "    z_noise = torch.randn(x_real.size(0), z_dim, 1, 1, device = device)\n",
        "    x_fake = netG(z_noise)\n",
        "    y_fake = netD(x_fake.detach())\n",
        "    loss_D_fake = criterion(y_fake, f_label)\n",
        "    loss_D_fake.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    # update G with fake data\n",
        "    netG.zero_grad()\n",
        "    y_fake_r = netD(x_fake)\n",
        "    loss_G = criterion(y_fake_r, r_label)\n",
        "    loss_G.backward()\n",
        "    optimizerG.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(\n",
        "          epoch, i, len(dataloader), loss_D_real.mean().item(),\n",
        "          loss_D_fake.mean().item(), loss_G.mean().item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm7smQi6gCK-",
        "outputId": "19412f46-c96d-4602-b9af-0783a47fca1a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 [0/469] loss_D_real: 0.0029 loss_D_fake: 0.0009 loss_G: 9.0288\n",
            "Epoch 0 [100/469] loss_D_real: 0.1162 loss_D_fake: 0.0003 loss_G: 10.1925\n",
            "Epoch 0 [200/469] loss_D_real: 0.0493 loss_D_fake: 0.2732 loss_G: 5.9532\n",
            "Epoch 0 [300/469] loss_D_real: 0.6122 loss_D_fake: 0.1446 loss_G: 2.0974\n",
            "Epoch 0 [400/469] loss_D_real: 0.1040 loss_D_fake: 0.0904 loss_G: 3.1931\n",
            "Epoch 1 [0/469] loss_D_real: 0.1060 loss_D_fake: 0.0372 loss_G: 3.2244\n",
            "Epoch 1 [100/469] loss_D_real: 0.1059 loss_D_fake: 0.0300 loss_G: 3.0169\n",
            "Epoch 1 [200/469] loss_D_real: 0.2238 loss_D_fake: 0.6994 loss_G: 2.4287\n",
            "Epoch 1 [300/469] loss_D_real: 0.2864 loss_D_fake: 0.1179 loss_G: 1.7449\n",
            "Epoch 1 [400/469] loss_D_real: 0.1974 loss_D_fake: 0.1779 loss_G: 2.3498\n",
            "Epoch 2 [0/469] loss_D_real: 0.4885 loss_D_fake: 0.0925 loss_G: 1.3059\n",
            "Epoch 2 [100/469] loss_D_real: 0.1484 loss_D_fake: 0.1983 loss_G: 2.6069\n",
            "Epoch 2 [200/469] loss_D_real: 0.1991 loss_D_fake: 0.3089 loss_G: 2.1731\n",
            "Epoch 2 [300/469] loss_D_real: 0.1238 loss_D_fake: 0.2224 loss_G: 3.1530\n",
            "Epoch 2 [400/469] loss_D_real: 0.0960 loss_D_fake: 0.2554 loss_G: 2.8962\n",
            "Epoch 3 [0/469] loss_D_real: 0.0599 loss_D_fake: 0.1598 loss_G: 3.8428\n",
            "Epoch 3 [100/469] loss_D_real: 0.1799 loss_D_fake: 0.0628 loss_G: 2.7631\n",
            "Epoch 3 [200/469] loss_D_real: 0.0575 loss_D_fake: 0.1125 loss_G: 3.4420\n",
            "Epoch 3 [300/469] loss_D_real: 0.0982 loss_D_fake: 0.1127 loss_G: 3.4381\n",
            "Epoch 3 [400/469] loss_D_real: 0.0645 loss_D_fake: 0.0884 loss_G: 3.9563\n",
            "Epoch 4 [0/469] loss_D_real: 0.1196 loss_D_fake: 0.1336 loss_G: 3.2516\n",
            "Epoch 4 [100/469] loss_D_real: 0.0479 loss_D_fake: 0.1297 loss_G: 4.1385\n",
            "Epoch 4 [200/469] loss_D_real: 0.0993 loss_D_fake: 0.0760 loss_G: 4.1401\n",
            "Epoch 4 [300/469] loss_D_real: 0.1268 loss_D_fake: 0.5997 loss_G: 3.1195\n",
            "Epoch 4 [400/469] loss_D_real: 0.0687 loss_D_fake: 0.7391 loss_G: 4.6108\n",
            "Epoch 5 [0/469] loss_D_real: 0.7312 loss_D_fake: 0.0288 loss_G: 3.3199\n",
            "Epoch 5 [100/469] loss_D_real: 0.0271 loss_D_fake: 1.6054 loss_G: 5.8638\n",
            "Epoch 5 [200/469] loss_D_real: 0.0859 loss_D_fake: 0.0130 loss_G: 3.5780\n",
            "Epoch 5 [300/469] loss_D_real: 0.1310 loss_D_fake: 0.4071 loss_G: 3.7256\n",
            "Epoch 5 [400/469] loss_D_real: 0.0866 loss_D_fake: 0.0142 loss_G: 3.5095\n",
            "Epoch 6 [0/469] loss_D_real: 0.1604 loss_D_fake: 0.0227 loss_G: 4.0925\n",
            "Epoch 6 [100/469] loss_D_real: 0.0808 loss_D_fake: 0.1130 loss_G: 3.4584\n",
            "Epoch 6 [200/469] loss_D_real: 0.0590 loss_D_fake: 0.0493 loss_G: 3.1532\n",
            "Epoch 6 [300/469] loss_D_real: 0.2701 loss_D_fake: 0.0718 loss_G: 2.3231\n",
            "Epoch 6 [400/469] loss_D_real: 0.1406 loss_D_fake: 0.0524 loss_G: 2.6577\n",
            "Epoch 7 [0/469] loss_D_real: 0.0181 loss_D_fake: 0.0256 loss_G: 4.2742\n",
            "Epoch 7 [100/469] loss_D_real: 0.1165 loss_D_fake: 0.1512 loss_G: 3.7552\n",
            "Epoch 7 [200/469] loss_D_real: 0.1462 loss_D_fake: 0.0433 loss_G: 3.4784\n",
            "Epoch 7 [300/469] loss_D_real: 0.8234 loss_D_fake: 0.0022 loss_G: 1.7488\n",
            "Epoch 7 [400/469] loss_D_real: 0.0348 loss_D_fake: 0.0210 loss_G: 4.1827\n",
            "Epoch 8 [0/469] loss_D_real: 0.0218 loss_D_fake: 0.0114 loss_G: 4.5538\n",
            "Epoch 8 [100/469] loss_D_real: 0.1583 loss_D_fake: 0.4300 loss_G: 2.0464\n",
            "Epoch 8 [200/469] loss_D_real: 0.1219 loss_D_fake: 0.3438 loss_G: 3.6656\n",
            "Epoch 8 [300/469] loss_D_real: 0.1421 loss_D_fake: 0.0455 loss_G: 3.3851\n",
            "Epoch 8 [400/469] loss_D_real: 0.0379 loss_D_fake: 0.0559 loss_G: 3.5957\n",
            "Epoch 9 [0/469] loss_D_real: 0.2330 loss_D_fake: 0.2561 loss_G: 2.4870\n",
            "Epoch 9 [100/469] loss_D_real: 0.0211 loss_D_fake: 0.0812 loss_G: 5.0674\n",
            "Epoch 9 [200/469] loss_D_real: 0.1105 loss_D_fake: 0.1200 loss_G: 3.1188\n",
            "Epoch 9 [300/469] loss_D_real: 0.0785 loss_D_fake: 0.0764 loss_G: 3.6503\n",
            "Epoch 9 [400/469] loss_D_real: 0.1315 loss_D_fake: 0.1882 loss_G: 3.2121\n",
            "Epoch 10 [0/469] loss_D_real: 0.1912 loss_D_fake: 0.0965 loss_G: 2.5377\n",
            "Epoch 10 [100/469] loss_D_real: 0.0497 loss_D_fake: 0.0268 loss_G: 3.9443\n",
            "Epoch 10 [200/469] loss_D_real: 0.2432 loss_D_fake: 0.2666 loss_G: 2.8001\n",
            "Epoch 10 [300/469] loss_D_real: 0.0440 loss_D_fake: 0.0338 loss_G: 4.0153\n",
            "Epoch 10 [400/469] loss_D_real: 0.3479 loss_D_fake: 1.1429 loss_G: 1.2585\n",
            "Epoch 11 [0/469] loss_D_real: 0.3693 loss_D_fake: 0.0510 loss_G: 1.7963\n",
            "Epoch 11 [100/469] loss_D_real: 0.2405 loss_D_fake: 0.1752 loss_G: 2.1858\n",
            "Epoch 11 [200/469] loss_D_real: 1.1446 loss_D_fake: 0.1951 loss_G: 0.9405\n",
            "Epoch 11 [300/469] loss_D_real: 0.1922 loss_D_fake: 0.1606 loss_G: 3.1324\n",
            "Epoch 11 [400/469] loss_D_real: 0.0428 loss_D_fake: 0.0178 loss_G: 4.3523\n",
            "Epoch 12 [0/469] loss_D_real: 0.0114 loss_D_fake: 0.0153 loss_G: 4.5462\n",
            "Epoch 12 [100/469] loss_D_real: 1.3620 loss_D_fake: 0.0120 loss_G: 1.5906\n",
            "Epoch 12 [200/469] loss_D_real: 0.0848 loss_D_fake: 0.2312 loss_G: 4.2636\n",
            "Epoch 12 [300/469] loss_D_real: 0.4917 loss_D_fake: 0.0360 loss_G: 2.4636\n",
            "Epoch 12 [400/469] loss_D_real: 0.0360 loss_D_fake: 0.0285 loss_G: 4.3152\n",
            "Epoch 13 [0/469] loss_D_real: 0.0110 loss_D_fake: 0.0229 loss_G: 4.4039\n",
            "Epoch 13 [100/469] loss_D_real: 14.9491 loss_D_fake: 0.0000 loss_G: 3.6905\n",
            "Epoch 13 [200/469] loss_D_real: 0.0534 loss_D_fake: 0.0679 loss_G: 3.5011\n",
            "Epoch 13 [300/469] loss_D_real: 0.6594 loss_D_fake: 0.2190 loss_G: 1.9219\n",
            "Epoch 13 [400/469] loss_D_real: 0.0488 loss_D_fake: 0.0507 loss_G: 3.7717\n",
            "Epoch 14 [0/469] loss_D_real: 0.0062 loss_D_fake: 0.1079 loss_G: 6.0816\n",
            "Epoch 14 [100/469] loss_D_real: 0.6735 loss_D_fake: 0.2575 loss_G: 1.3155\n",
            "Epoch 14 [200/469] loss_D_real: 1.0394 loss_D_fake: 0.0176 loss_G: 0.8471\n",
            "Epoch 14 [300/469] loss_D_real: 0.0239 loss_D_fake: 0.0338 loss_G: 4.3247\n",
            "Epoch 14 [400/469] loss_D_real: 1.0326 loss_D_fake: 0.1657 loss_G: 1.0103\n",
            "Epoch 15 [0/469] loss_D_real: 0.2256 loss_D_fake: 0.0656 loss_G: 3.9411\n",
            "Epoch 15 [100/469] loss_D_real: 0.2181 loss_D_fake: 0.0399 loss_G: 2.0160\n",
            "Epoch 15 [200/469] loss_D_real: 0.0475 loss_D_fake: 0.0082 loss_G: 4.0008\n",
            "Epoch 15 [300/469] loss_D_real: 0.0098 loss_D_fake: 0.0111 loss_G: 5.0971\n",
            "Epoch 15 [400/469] loss_D_real: 0.0290 loss_D_fake: 0.0778 loss_G: 3.8559\n",
            "Epoch 16 [0/469] loss_D_real: 0.0157 loss_D_fake: 0.2889 loss_G: 5.4281\n",
            "Epoch 16 [100/469] loss_D_real: 0.0156 loss_D_fake: 0.0290 loss_G: 4.6754\n",
            "Epoch 16 [200/469] loss_D_real: 0.0055 loss_D_fake: 0.0387 loss_G: 6.4438\n",
            "Epoch 16 [300/469] loss_D_real: 3.5153 loss_D_fake: 0.0021 loss_G: 0.7339\n",
            "Epoch 16 [400/469] loss_D_real: 0.0411 loss_D_fake: 1.2428 loss_G: 5.5730\n",
            "Epoch 17 [0/469] loss_D_real: 0.0652 loss_D_fake: 0.0416 loss_G: 4.2207\n",
            "Epoch 17 [100/469] loss_D_real: 0.1714 loss_D_fake: 0.1464 loss_G: 2.8126\n",
            "Epoch 17 [200/469] loss_D_real: 0.2049 loss_D_fake: 0.0570 loss_G: 2.2998\n",
            "Epoch 17 [300/469] loss_D_real: 0.0141 loss_D_fake: 0.0468 loss_G: 5.0571\n",
            "Epoch 17 [400/469] loss_D_real: 0.0114 loss_D_fake: 0.0141 loss_G: 5.3014\n",
            "Epoch 18 [0/469] loss_D_real: 0.1069 loss_D_fake: 2.5363 loss_G: 1.7175\n",
            "Epoch 18 [100/469] loss_D_real: 0.1031 loss_D_fake: 0.0932 loss_G: 3.0237\n",
            "Epoch 18 [200/469] loss_D_real: 0.0756 loss_D_fake: 1.3228 loss_G: 6.3755\n",
            "Epoch 18 [300/469] loss_D_real: 0.0387 loss_D_fake: 0.0333 loss_G: 4.2152\n",
            "Epoch 18 [400/469] loss_D_real: 0.0339 loss_D_fake: 0.0300 loss_G: 4.2556\n",
            "Epoch 19 [0/469] loss_D_real: 0.0338 loss_D_fake: 0.0064 loss_G: 4.8518\n",
            "Epoch 19 [100/469] loss_D_real: 0.0142 loss_D_fake: 0.0092 loss_G: 5.0222\n",
            "Epoch 19 [200/469] loss_D_real: 0.0066 loss_D_fake: 0.0050 loss_G: 5.9401\n",
            "Epoch 19 [300/469] loss_D_real: 0.0056 loss_D_fake: 0.0152 loss_G: 5.6025\n",
            "Epoch 19 [400/469] loss_D_real: 0.1822 loss_D_fake: 0.2931 loss_G: 2.6255\n",
            "Epoch 20 [0/469] loss_D_real: 0.0505 loss_D_fake: 0.3517 loss_G: 4.8390\n",
            "Epoch 20 [100/469] loss_D_real: 0.0410 loss_D_fake: 0.1255 loss_G: 4.2836\n",
            "Epoch 20 [200/469] loss_D_real: 0.0177 loss_D_fake: 0.0226 loss_G: 4.7311\n",
            "Epoch 20 [300/469] loss_D_real: 0.2130 loss_D_fake: 0.0789 loss_G: 2.5133\n",
            "Epoch 20 [400/469] loss_D_real: 0.1167 loss_D_fake: 0.0479 loss_G: 4.0768\n",
            "Epoch 21 [0/469] loss_D_real: 0.0354 loss_D_fake: 0.0567 loss_G: 4.8421\n",
            "Epoch 21 [100/469] loss_D_real: 0.0068 loss_D_fake: 0.0077 loss_G: 5.2731\n",
            "Epoch 21 [200/469] loss_D_real: 0.3462 loss_D_fake: 0.1537 loss_G: 2.4090\n",
            "Epoch 21 [300/469] loss_D_real: 0.0617 loss_D_fake: 0.1707 loss_G: 3.9170\n",
            "Epoch 21 [400/469] loss_D_real: 0.0461 loss_D_fake: 1.8266 loss_G: 2.9939\n",
            "Epoch 22 [0/469] loss_D_real: 0.0364 loss_D_fake: 0.1803 loss_G: 4.5021\n",
            "Epoch 22 [100/469] loss_D_real: 0.0164 loss_D_fake: 0.0131 loss_G: 4.8813\n",
            "Epoch 22 [200/469] loss_D_real: 0.0060 loss_D_fake: 0.0123 loss_G: 5.4559\n",
            "Epoch 22 [300/469] loss_D_real: 0.0055 loss_D_fake: 0.0087 loss_G: 6.0356\n",
            "Epoch 22 [400/469] loss_D_real: 0.4450 loss_D_fake: 0.4467 loss_G: 1.2473\n",
            "Epoch 23 [0/469] loss_D_real: 0.1250 loss_D_fake: 0.4623 loss_G: 3.4538\n",
            "Epoch 23 [100/469] loss_D_real: 0.0391 loss_D_fake: 0.3479 loss_G: 4.6507\n",
            "Epoch 23 [200/469] loss_D_real: 0.2562 loss_D_fake: 0.0148 loss_G: 3.3845\n",
            "Epoch 23 [300/469] loss_D_real: 0.0288 loss_D_fake: 0.0233 loss_G: 4.6826\n",
            "Epoch 23 [400/469] loss_D_real: 0.3725 loss_D_fake: 0.2438 loss_G: 1.7993\n",
            "Epoch 24 [0/469] loss_D_real: 0.0463 loss_D_fake: 0.0907 loss_G: 3.5468\n",
            "Epoch 24 [100/469] loss_D_real: 0.0222 loss_D_fake: 0.0135 loss_G: 4.4640\n",
            "Epoch 24 [200/469] loss_D_real: 0.0145 loss_D_fake: 0.0176 loss_G: 4.6515\n",
            "Epoch 24 [300/469] loss_D_real: 0.2442 loss_D_fake: 0.9212 loss_G: 1.8391\n",
            "Epoch 24 [400/469] loss_D_real: 0.4105 loss_D_fake: 0.1867 loss_G: 2.0398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Learning!!!\n",
        "\n",
        "viz_noise = torch.randn(batch_size, z_dim, 1, 1, device = device)\n",
        "\n",
        "for epoch in range(epoch_num):\n",
        "  for i, data in enumerate(dataloader):\n",
        "    x_real = data[0].to(device)\n",
        "    r_label = torch.full((x_real.size(0),), real_label, device = device).float()\n",
        "    f_label = torch.full((x_real.size(0),), fake_label, device = device).float()\n",
        "\n",
        "    # update D with real data\n",
        "    netD.zero_grad()\n",
        "    y_real = netD(x_real)\n",
        "\n",
        "    loss_D_real = criterion(y_real, r_label)\n",
        "    loss_D_real.backward()\n",
        "\n",
        "    # update D with fake data\n",
        "    z_noise = torch.randn(x_real.size(0), z_dim, 1, 1, device = device)\n",
        "    x_fake = netG(z_noise)\n",
        "    y_fake = netD(x_fake.detach())\n",
        "    loss_D_fake = criterion(y_fake, f_label)\n",
        "    loss_D_fake.backward()\n",
        "    optimizerD.step()\n",
        "\n",
        "    # update G with fake data\n",
        "    netG.zero_grad()\n",
        "    y_fake_r = netD(x_fake)\n",
        "    loss_G = criterion(y_fake_r, r_label)\n",
        "    loss_G.backward()\n",
        "    optimizerG.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(\n",
        "          epoch, i, len(dataloader), loss_D_real.mean().item(),\n",
        "          loss_D_fake.mean().item(), loss_G.mean().item()\n",
        "      ))\n",
        "      \n",
        "      vutils.save_image(x_real, os.path.join(out_path, 'real_samples_{}.png'.format(epoch)), normalize = True)\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        viz_sample = netG(viz_noise)\n",
        "        vutils.save_image(viz_sample, os.path.join(out_path, 'fake_samples_{}.png'.format(epoch)), normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqOB18N0gCl2",
        "outputId": "a26e8038-5216-463c-dc45-df551218b2f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 [0/469] loss_D_real: 0.7623 loss_D_fake: 0.8161 loss_G: 4.0889\n",
            "Epoch 0 [100/469] loss_D_real: 0.0001 loss_D_fake: 0.0000 loss_G: 37.4320\n",
            "Epoch 0 [200/469] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 36.6530\n",
            "Epoch 0 [300/469] loss_D_real: 0.0115 loss_D_fake: 0.6389 loss_G: 6.1193\n",
            "Epoch 0 [400/469] loss_D_real: 0.1142 loss_D_fake: 0.2773 loss_G: 3.0660\n",
            "Epoch 1 [0/469] loss_D_real: 5.6465 loss_D_fake: 0.0009 loss_G: 0.0120\n",
            "Epoch 1 [100/469] loss_D_real: 0.0904 loss_D_fake: 0.1984 loss_G: 3.0611\n",
            "Epoch 1 [200/469] loss_D_real: 0.0640 loss_D_fake: 0.4349 loss_G: 3.8013\n",
            "Epoch 1 [300/469] loss_D_real: 0.0446 loss_D_fake: 0.6368 loss_G: 3.9069\n",
            "Epoch 1 [400/469] loss_D_real: 0.1867 loss_D_fake: 0.5579 loss_G: 2.5529\n",
            "Epoch 2 [0/469] loss_D_real: 0.2262 loss_D_fake: 0.5700 loss_G: 1.9528\n",
            "Epoch 2 [100/469] loss_D_real: 0.1565 loss_D_fake: 0.3080 loss_G: 2.4902\n",
            "Epoch 2 [200/469] loss_D_real: 0.8986 loss_D_fake: 0.0398 loss_G: 0.9957\n",
            "Epoch 2 [300/469] loss_D_real: 0.0806 loss_D_fake: 0.1753 loss_G: 3.1974\n",
            "Epoch 2 [400/469] loss_D_real: 0.1409 loss_D_fake: 0.2245 loss_G: 2.6979\n",
            "Epoch 3 [0/469] loss_D_real: 0.9133 loss_D_fake: 0.0176 loss_G: 1.1637\n",
            "Epoch 3 [100/469] loss_D_real: 0.1872 loss_D_fake: 0.0869 loss_G: 2.6850\n",
            "Epoch 3 [200/469] loss_D_real: 0.9348 loss_D_fake: 0.1131 loss_G: 1.9484\n",
            "Epoch 3 [300/469] loss_D_real: 0.2343 loss_D_fake: 0.1837 loss_G: 2.4800\n",
            "Epoch 3 [400/469] loss_D_real: 0.1366 loss_D_fake: 0.0969 loss_G: 2.5639\n",
            "Epoch 4 [0/469] loss_D_real: 0.3576 loss_D_fake: 0.0037 loss_G: 1.5736\n",
            "Epoch 4 [100/469] loss_D_real: 0.4238 loss_D_fake: 0.0145 loss_G: 1.6674\n",
            "Epoch 4 [200/469] loss_D_real: 0.0103 loss_D_fake: 0.8941 loss_G: 7.4218\n",
            "Epoch 4 [300/469] loss_D_real: 0.1161 loss_D_fake: 0.0537 loss_G: 3.0352\n",
            "Epoch 4 [400/469] loss_D_real: 0.5808 loss_D_fake: 0.1939 loss_G: 0.7703\n",
            "Epoch 5 [0/469] loss_D_real: 0.0274 loss_D_fake: 0.7675 loss_G: 4.7788\n",
            "Epoch 5 [100/469] loss_D_real: 0.2215 loss_D_fake: 0.2967 loss_G: 2.1585\n",
            "Epoch 5 [200/469] loss_D_real: 0.1715 loss_D_fake: 0.5768 loss_G: 3.3159\n",
            "Epoch 5 [300/469] loss_D_real: 0.6077 loss_D_fake: 0.1239 loss_G: 1.2390\n",
            "Epoch 5 [400/469] loss_D_real: 0.0382 loss_D_fake: 0.0477 loss_G: 3.9487\n",
            "Epoch 6 [0/469] loss_D_real: 0.0598 loss_D_fake: 0.2359 loss_G: 4.0201\n",
            "Epoch 6 [100/469] loss_D_real: 0.0225 loss_D_fake: 0.0833 loss_G: 4.6577\n",
            "Epoch 6 [200/469] loss_D_real: 0.3131 loss_D_fake: 0.1026 loss_G: 1.9191\n",
            "Epoch 6 [300/469] loss_D_real: 0.6626 loss_D_fake: 0.0395 loss_G: 2.5172\n",
            "Epoch 6 [400/469] loss_D_real: 0.0729 loss_D_fake: 0.0490 loss_G: 3.6844\n",
            "Epoch 7 [0/469] loss_D_real: 0.7465 loss_D_fake: 0.1083 loss_G: 0.7860\n",
            "Epoch 7 [100/469] loss_D_real: 0.0264 loss_D_fake: 0.0783 loss_G: 4.2092\n",
            "Epoch 7 [200/469] loss_D_real: 0.0685 loss_D_fake: 0.1791 loss_G: 3.8650\n",
            "Epoch 7 [300/469] loss_D_real: 0.0268 loss_D_fake: 0.0540 loss_G: 4.1156\n",
            "Epoch 7 [400/469] loss_D_real: 0.0279 loss_D_fake: 0.7916 loss_G: 7.4067\n",
            "Epoch 8 [0/469] loss_D_real: 0.0338 loss_D_fake: 0.1385 loss_G: 3.0516\n",
            "Epoch 8 [100/469] loss_D_real: 0.1148 loss_D_fake: 0.5562 loss_G: 3.3339\n",
            "Epoch 8 [200/469] loss_D_real: 0.0464 loss_D_fake: 0.0562 loss_G: 3.9664\n",
            "Epoch 8 [300/469] loss_D_real: 0.0023 loss_D_fake: 0.4103 loss_G: 15.5274\n",
            "Epoch 8 [400/469] loss_D_real: 0.3841 loss_D_fake: 0.1216 loss_G: 1.9878\n",
            "Epoch 9 [0/469] loss_D_real: 0.0267 loss_D_fake: 0.7888 loss_G: 6.3082\n",
            "Epoch 9 [100/469] loss_D_real: 0.0329 loss_D_fake: 0.0528 loss_G: 4.2773\n",
            "Epoch 9 [200/469] loss_D_real: 0.2857 loss_D_fake: 0.5208 loss_G: 1.9276\n",
            "Epoch 9 [300/469] loss_D_real: 0.1535 loss_D_fake: 0.9058 loss_G: 4.2201\n",
            "Epoch 9 [400/469] loss_D_real: 0.2991 loss_D_fake: 0.0403 loss_G: 1.6757\n",
            "Epoch 10 [0/469] loss_D_real: 0.0356 loss_D_fake: 0.2704 loss_G: 4.4083\n",
            "Epoch 10 [100/469] loss_D_real: 0.0201 loss_D_fake: 0.0598 loss_G: 4.1846\n",
            "Epoch 10 [200/469] loss_D_real: 0.0111 loss_D_fake: 0.0392 loss_G: 4.4686\n",
            "Epoch 10 [300/469] loss_D_real: 0.2875 loss_D_fake: 0.3932 loss_G: 2.0345\n",
            "Epoch 10 [400/469] loss_D_real: 0.1498 loss_D_fake: 0.1010 loss_G: 2.5022\n",
            "Epoch 11 [0/469] loss_D_real: 0.0302 loss_D_fake: 0.0954 loss_G: 4.0538\n",
            "Epoch 11 [100/469] loss_D_real: 0.0450 loss_D_fake: 0.0331 loss_G: 3.8863\n",
            "Epoch 11 [200/469] loss_D_real: 0.1033 loss_D_fake: 0.0518 loss_G: 3.0164\n",
            "Epoch 11 [300/469] loss_D_real: 0.7530 loss_D_fake: 0.2896 loss_G: 1.0004\n",
            "Epoch 11 [400/469] loss_D_real: 0.2796 loss_D_fake: 0.1603 loss_G: 2.9316\n",
            "Epoch 12 [0/469] loss_D_real: 0.0720 loss_D_fake: 0.0494 loss_G: 3.4804\n",
            "Epoch 12 [100/469] loss_D_real: 0.4040 loss_D_fake: 0.5041 loss_G: 1.6305\n",
            "Epoch 12 [200/469] loss_D_real: 0.0806 loss_D_fake: 0.2445 loss_G: 3.5060\n",
            "Epoch 12 [300/469] loss_D_real: 0.0354 loss_D_fake: 0.0320 loss_G: 3.8978\n",
            "Epoch 12 [400/469] loss_D_real: 0.1126 loss_D_fake: 0.0123 loss_G: 3.8825\n",
            "Epoch 13 [0/469] loss_D_real: 1.3047 loss_D_fake: 0.0497 loss_G: 0.7354\n",
            "Epoch 13 [100/469] loss_D_real: 0.0261 loss_D_fake: 0.0228 loss_G: 4.4666\n",
            "Epoch 13 [200/469] loss_D_real: 0.3235 loss_D_fake: 1.1711 loss_G: 1.5997\n",
            "Epoch 13 [300/469] loss_D_real: 0.0449 loss_D_fake: 0.7069 loss_G: 5.2355\n",
            "Epoch 13 [400/469] loss_D_real: 0.0534 loss_D_fake: 0.2162 loss_G: 3.7698\n",
            "Epoch 14 [0/469] loss_D_real: 0.0289 loss_D_fake: 0.0867 loss_G: 3.9942\n",
            "Epoch 14 [100/469] loss_D_real: 0.0172 loss_D_fake: 0.0221 loss_G: 4.8910\n",
            "Epoch 14 [200/469] loss_D_real: 0.6532 loss_D_fake: 0.0664 loss_G: 2.1191\n",
            "Epoch 14 [300/469] loss_D_real: 0.0380 loss_D_fake: 0.0580 loss_G: 3.6838\n",
            "Epoch 14 [400/469] loss_D_real: 1.3601 loss_D_fake: 0.0029 loss_G: 1.1512\n",
            "Epoch 15 [0/469] loss_D_real: 0.2877 loss_D_fake: 0.0818 loss_G: 1.7174\n",
            "Epoch 15 [100/469] loss_D_real: 0.0208 loss_D_fake: 0.0722 loss_G: 4.5223\n",
            "Epoch 15 [200/469] loss_D_real: 0.0225 loss_D_fake: 0.0082 loss_G: 4.4511\n",
            "Epoch 15 [300/469] loss_D_real: 0.0209 loss_D_fake: 0.0124 loss_G: 4.6544\n",
            "Epoch 15 [400/469] loss_D_real: 0.0040 loss_D_fake: 2.1579 loss_G: 4.7461\n",
            "Epoch 16 [0/469] loss_D_real: 0.4550 loss_D_fake: 0.2773 loss_G: 1.3728\n",
            "Epoch 16 [100/469] loss_D_real: 8.0254 loss_D_fake: 0.0001 loss_G: 3.9847\n",
            "Epoch 16 [200/469] loss_D_real: 0.0300 loss_D_fake: 0.4196 loss_G: 3.8705\n",
            "Epoch 16 [300/469] loss_D_real: 0.2478 loss_D_fake: 0.0555 loss_G: 2.6705\n",
            "Epoch 16 [400/469] loss_D_real: 0.0349 loss_D_fake: 0.0140 loss_G: 4.5473\n",
            "Epoch 17 [0/469] loss_D_real: 0.0098 loss_D_fake: 0.0235 loss_G: 4.9876\n",
            "Epoch 17 [100/469] loss_D_real: 0.0126 loss_D_fake: 0.0112 loss_G: 4.7158\n",
            "Epoch 17 [200/469] loss_D_real: 0.1650 loss_D_fake: 0.4955 loss_G: 2.8813\n",
            "Epoch 17 [300/469] loss_D_real: 0.1587 loss_D_fake: 0.0468 loss_G: 3.5401\n",
            "Epoch 17 [400/469] loss_D_real: 0.0117 loss_D_fake: 0.0760 loss_G: 4.5493\n",
            "Epoch 18 [0/469] loss_D_real: 0.8423 loss_D_fake: 0.0460 loss_G: 1.7962\n",
            "Epoch 18 [100/469] loss_D_real: 0.0600 loss_D_fake: 0.0410 loss_G: 3.5551\n",
            "Epoch 18 [200/469] loss_D_real: 0.6156 loss_D_fake: 0.8561 loss_G: 1.3176\n",
            "Epoch 18 [300/469] loss_D_real: 0.1007 loss_D_fake: 0.1154 loss_G: 3.3078\n",
            "Epoch 18 [400/469] loss_D_real: 0.0675 loss_D_fake: 0.0389 loss_G: 3.5599\n",
            "Epoch 19 [0/469] loss_D_real: 0.0146 loss_D_fake: 0.4618 loss_G: 6.0583\n",
            "Epoch 19 [100/469] loss_D_real: 0.0165 loss_D_fake: 0.0188 loss_G: 4.7099\n",
            "Epoch 19 [200/469] loss_D_real: 0.0115 loss_D_fake: 0.0200 loss_G: 5.0976\n",
            "Epoch 19 [300/469] loss_D_real: 0.5101 loss_D_fake: 0.6333 loss_G: 1.1006\n",
            "Epoch 19 [400/469] loss_D_real: 0.5949 loss_D_fake: 0.2911 loss_G: 1.2688\n",
            "Epoch 20 [0/469] loss_D_real: 0.5145 loss_D_fake: 0.1301 loss_G: 2.5614\n",
            "Epoch 20 [100/469] loss_D_real: 0.0932 loss_D_fake: 0.0637 loss_G: 3.1113\n",
            "Epoch 20 [200/469] loss_D_real: 0.0105 loss_D_fake: 0.0971 loss_G: 5.6046\n",
            "Epoch 20 [300/469] loss_D_real: 0.0452 loss_D_fake: 0.1733 loss_G: 3.5808\n",
            "Epoch 20 [400/469] loss_D_real: 0.0749 loss_D_fake: 0.1027 loss_G: 3.8159\n",
            "Epoch 21 [0/469] loss_D_real: 0.0190 loss_D_fake: 0.0317 loss_G: 4.4823\n",
            "Epoch 21 [100/469] loss_D_real: 0.0175 loss_D_fake: 0.0077 loss_G: 4.9950\n",
            "Epoch 21 [200/469] loss_D_real: 0.0034 loss_D_fake: 0.0659 loss_G: 6.8225\n",
            "Epoch 21 [300/469] loss_D_real: 0.0822 loss_D_fake: 0.1949 loss_G: 3.2297\n",
            "Epoch 21 [400/469] loss_D_real: 0.0275 loss_D_fake: 0.0533 loss_G: 4.3723\n",
            "Epoch 22 [0/469] loss_D_real: 0.0555 loss_D_fake: 0.0197 loss_G: 4.1592\n",
            "Epoch 22 [100/469] loss_D_real: 0.0087 loss_D_fake: 0.0132 loss_G: 5.1058\n",
            "Epoch 22 [200/469] loss_D_real: 0.0092 loss_D_fake: 0.0031 loss_G: 5.8716\n",
            "Epoch 22 [300/469] loss_D_real: 0.0080 loss_D_fake: 0.0081 loss_G: 5.4945\n",
            "Epoch 22 [400/469] loss_D_real: 0.1270 loss_D_fake: 0.3538 loss_G: 2.4912\n",
            "Epoch 23 [0/469] loss_D_real: 0.0006 loss_D_fake: 2.2774 loss_G: 11.4348\n",
            "Epoch 23 [100/469] loss_D_real: 0.0026 loss_D_fake: 0.4633 loss_G: 7.7073\n",
            "Epoch 23 [200/469] loss_D_real: 0.4931 loss_D_fake: 0.0155 loss_G: 0.8037\n",
            "Epoch 23 [300/469] loss_D_real: 0.1183 loss_D_fake: 0.0439 loss_G: 2.9492\n",
            "Epoch 23 [400/469] loss_D_real: 0.0046 loss_D_fake: 0.0143 loss_G: 5.1396\n",
            "Epoch 24 [0/469] loss_D_real: 0.0106 loss_D_fake: 0.0188 loss_G: 5.0424\n",
            "Epoch 24 [100/469] loss_D_real: 0.0307 loss_D_fake: 0.0036 loss_G: 3.4624\n",
            "Epoch 24 [200/469] loss_D_real: 0.1276 loss_D_fake: 0.4944 loss_G: 3.2118\n",
            "Epoch 24 [300/469] loss_D_real: 0.1564 loss_D_fake: 0.1579 loss_G: 2.5676\n",
            "Epoch 24 [400/469] loss_D_real: 0.0130 loss_D_fake: 0.1807 loss_G: 4.5373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6D8nq_zG01K9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}